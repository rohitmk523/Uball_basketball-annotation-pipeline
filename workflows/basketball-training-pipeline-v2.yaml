# Basketball Training Pipeline V2 - Cloud Functions Architecture
# This workflow uses Cloud Functions instead of Cloud Run Jobs for better scalability

main:
  params: [args]
  steps:
    - init:
        assign:
          - game_ids: ${args.game_ids}
          - project_id: "refined-circuit-474617-s8"
          - region: "us-central1"
          - timestamp: ${string(int(sys.now()))}
          - execution_dir: ${"cumulative-execution-" + timestamp}
          - base_model: "gemini-2.5-pro"
          - model_prefix: "basketball-pro"
          - function_url: "https://us-central1-refined-circuit-474617-s8.cloudfunctions.net/extract-clips-game"

    - log_start:
        call: sys.log
        args:
          data: '${"üöÄ Starting cumulative training for " + string(len(game_ids)) + " games"}'
          severity: INFO

    # Step 1: Extract clips for all games in PARALLEL using Cloud Functions
    - extract_all_games:
        parallel:
          for:
            value: game_id
            in: ${game_ids}
            steps:
              - log_game_start:
                  call: sys.log
                  args:
                    data: '${"üé¨ Processing game: " + game_id}'
                    severity: INFO

              - call_extract_function:
                  try:
                    call: http.post
                    args:
                      url: ${function_url}
                      auth:
                        type: OAuth2
                      headers:
                        Content-Type: "application/json"
                      body:
                        game_id: ${game_id}
                      timeout: 3600
                    result: function_response
                  except:
                    as: e
                    steps:
                      - log_error:
                          call: sys.log
                          args:
                            data: '${"‚ùå Failed to process game " + game_id + ": " + e.message}'
                            severity: ERROR
                      - assign_error:
                          assign:
                            - function_response:
                                body:
                                  success: false
                                  error: ${e.message}
                                  game_id: ${game_id}

              - log_game_complete:
                  switch:
                    - condition: '${"clips_extracted" in function_response.body}'
                      steps:
                        - log_success_details:
                            call: sys.log
                            args:
                              data: '${"‚úÖ Completed game: " + game_id + " | Clips: " + string(function_response.body.clips_extracted) + "/" + string(function_response.body.clips_needed)}'
                              severity: INFO
                    - condition: true
                      steps:
                        - log_basic_complete:
                            call: sys.log
                            args:
                              data: '${"‚úÖ Game processing complete: " + game_id}'
                              severity: INFO

    - log_extraction_complete:
        call: sys.log
        args:
          data: "üéâ All games processed! Starting JSONL combination..."
          severity: INFO

    # Step 2: Combine JSONL files from all games
    - set_game_variables:
        assign:
          - game_ids_str: ""

    - build_game_ids_string:
        for:
          value: game_id
          in: ${game_ids}
          steps:
            - append_game_id:
                assign:
                  - game_ids_str: ${game_ids_str + game_id + ","}

    - combine_files:
        call: googleapis.run.v1.namespaces.jobs.create
        args:
          parent: '${"namespaces/" + project_id}'
          location: ${region}
          body:
            apiVersion: run.googleapis.com/v1
            kind: Job
            metadata:
              name: '${"combine-" + timestamp}'
            spec:
              template:
                spec:
                  parallelism: 1
                  taskCount: 1
                  template:
                    spec:
                      containers:
                      - image: "gcr.io/google.com/cloudsdktool/cloud-sdk:latest"
                        command: ["/bin/bash"]
                        args:
                          - "-c"
                          - |
                            echo "üöÄ Combining JSONL files from all games..."

                            # Create execution directory
                            gsutil -m mkdir -p "gs://uball-training-data/${EXECUTION_DIR}/"

                            # Initialize combined files (empty, not blank line)
                            touch /tmp/combined_training.jsonl
                            touch /tmp/combined_validation.jsonl

                            # Process all games from comma-separated list
                            game_count=0
                            IFS=',' read -ra GAMES <<< "$GAME_IDS"
                            for game_id in "${GAMES[@]}"; do
                              game_count=$((game_count + 1))
                              echo "üìÇ Processing game $game_count: $game_id"

                              # Create game directory in execution folder
                              gsutil -m mkdir -p "gs://uball-training-data/${EXECUTION_DIR}/${game_id}/"

                              # Find and combine training files (get the most recent)
                              training_file=$(gsutil ls "gs://uball-training-data/games/$game_id/video_training_*.jsonl" 2>/dev/null | sort | tail -1 || echo "")
                              if [ -n "$training_file" ]; then
                                echo "üì• Downloading training file: $training_file"
                                gsutil cp "$training_file" "/tmp/game${game_count}_training.jsonl" 2>/dev/null || true
                                if [ -f "/tmp/game${game_count}_training.jsonl" ]; then
                                  cat "/tmp/game${game_count}_training.jsonl" >> /tmp/combined_training.jsonl
                                  echo "‚úÖ Added training data for game $game_id"
                                else
                                  echo "‚ùå Failed to download training file for game $game_id"
                                fi
                              else
                                echo "‚ö†Ô∏è No training file found for game $game_id"
                              fi

                              # Find and combine validation files (get the most recent)
                              validation_file=$(gsutil ls "gs://uball-training-data/games/$game_id/video_validation_*.jsonl" 2>/dev/null | sort | tail -1 || echo "")
                              if [ -n "$validation_file" ]; then
                                echo "üì• Downloading validation file: $validation_file"
                                gsutil cp "$validation_file" "/tmp/game${game_count}_validation.jsonl" 2>/dev/null || true
                                if [ -f "/tmp/game${game_count}_validation.jsonl" ]; then
                                  cat "/tmp/game${game_count}_validation.jsonl" >> /tmp/combined_validation.jsonl
                                  echo "‚úÖ Added validation data for game $game_id"
                                else
                                  echo "‚ùå Failed to download validation file for game $game_id"
                                fi
                              else
                                echo "‚ö†Ô∏è No validation file found for game $game_id"
                              fi
                            done

                            # Check if files have content
                            training_lines=$(wc -l < /tmp/combined_training.jsonl)
                            validation_lines=$(wc -l < /tmp/combined_validation.jsonl)

                            echo "üìä Summary:"
                            echo "  - Processed games: $game_count"
                            echo "  - Training examples: $training_lines"
                            echo "  - Validation examples: $validation_lines"

                            if [ "$training_lines" -eq 0 ]; then
                              echo "‚ùå No training data found! Cannot proceed."
                              exit 1
                            fi

                            # Upload combined files
                            echo "üì§ Uploading combined files..."
                            gsutil cp /tmp/combined_training.jsonl "gs://uball-training-data/${EXECUTION_DIR}/combined_training.jsonl"
                            gsutil cp /tmp/combined_validation.jsonl "gs://uball-training-data/${EXECUTION_DIR}/combined_validation.jsonl"

                            echo "‚úÖ Combined files ready with $game_count games!"
                        env:
                        - name: EXECUTION_DIR
                          value: ${execution_dir}
                        - name: GAME_IDS
                          value: ${game_ids_str}
                        resources:
                          limits:
                            memory: 4Gi
                            cpu: "2"
                      maxRetries: 3
                      timeoutSeconds: "1800"
        result: combine_job

    - run_combine_job:
        call: googleapis.run.v1.namespaces.jobs.run
        args:
          name: '${"namespaces/" + project_id + "/jobs/" + combine_job.metadata.name}'
          location: ${region}
        result: combine_execution

    - wait_combine:
        call: wait_job_complete
        args:
          execution_name: ${combine_execution.metadata.name}
          project_id: ${project_id}

    # Step 3: Start Vertex AI tuning
    - set_file_paths:
        assign:
          - training_file: '${"gs://uball-training-data/" + execution_dir + "/combined_training.jsonl"}'
          - validation_file: '${"gs://uball-training-data/" + execution_dir + "/combined_validation.jsonl"}'

    - create_tuning_job:
        call: http.post
        args:
          url: '${"https://" + region + "-aiplatform.googleapis.com/v1/projects/" + project_id + "/locations/" + region + "/tuningJobs"}'
          auth:
            type: OAuth2
          headers:
            Content-Type: "application/json"
          body:
            baseModel: ${base_model}
            supervisedTuningSpec:
              trainingDatasetUri: ${training_file}
              validationDatasetUri: ${validation_file}
              hyperParameters:
                epochCount: "5"
                learningRateMultiplier: "1.0"
                adapterSize: "ADAPTER_SIZE_ONE"
            tunedModelDisplayName: '${"" + model_prefix + "-cumulative-" + string(len(game_ids)) + "games-" + timestamp}'
            description: '${"Cumulative training on " + string(len(game_ids)) + " games using " + base_model}'
        result: tuning_response

    - log_tuning_started:
        call: sys.log
        args:
          data: '${"ü§ñ Started tuning job: " + tuning_response.body.name}'
          severity: INFO

    # Monitor tuning completion
    - wait_tuning:
        call: monitor_tuning
        args:
          job_name: ${tuning_response.body.name}

    - log_success:
        call: sys.log
        args:
          data: '${"üéâ Cumulative training completed for " + string(len(game_ids)) + " games!"}'
          severity: INFO

    - return_result:
        return:
          success: true
          games_trained: ${game_ids}
          total_games: ${len(game_ids)}
          training_file: ${training_file}
          validation_file: ${validation_file}
          execution_directory: ${execution_dir}

# Wait for job completion
wait_job_complete:
  params: [execution_name, project_id]
  steps:
    - poll_loop:
        assign:
          - iterations: 0
          - max_iterations: 120  # 30s * 120 = 60 minutes
    - check_status:
        call: googleapis.run.v1.namespaces.executions.get
        args:
          name: '${"namespaces/" + project_id + "/executions/" + execution_name}'
          location: us-central1
        result: status
    - evaluate_status:
        switch:
          - condition: ${len(status.status.conditions) > 0 and status.status.conditions[0].type == "Completed"}
            return: ${status}
          - condition: ${len(status.status.conditions) > 0 and status.status.conditions[0].type == "Failed"}
            raise: '${"Execution failed: " + status.status.conditions[0].message}'
          - condition: ${iterations >= max_iterations}
            raise: "Execution timed out"
    - wait_and_retry:
        call: sys.sleep
        args:
          seconds: 30
    - increment_and_continue:
        assign:
          - iterations: ${iterations + 1}
        next: check_status

# Monitor tuning job
monitor_tuning:
  params: [job_name]
  steps:
    - poll_loop:
        assign:
          - iterations: 0
          - max_iterations: 480  # 1 minute * 480 = 8 hours
    - check_tuning:
        call: http.get
        args:
          url: '${"https://us-central1-aiplatform.googleapis.com/v1/" + job_name}'
          auth:
            type: OAuth2
        result: tuning_status
    - evaluate_tuning:
        switch:
          - condition: ${tuning_status.body.state == "JOB_STATE_SUCCEEDED"}
            return:
              success: true
              tuned_model: ${tuning_status.body.tunedModel.model}
          - condition: ${tuning_status.body.state == "JOB_STATE_FAILED"}
            raise: '${"Tuning failed: " + tuning_status.body.error.message}'
          - condition: ${iterations >= max_iterations}
            raise: "Tuning timed out"
    - wait_and_retry:
        call: sys.sleep
        args:
          seconds: 60
    - increment_and_continue:
        assign:
          - iterations: ${iterations + 1}
        next: check_tuning

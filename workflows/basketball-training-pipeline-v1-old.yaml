# Simplified Cumulative Training Pipeline - Clean Version
main:
  params: [args]
  steps:
    - init:
        assign:
          - game_ids: ${args.game_ids}
          - project_id: "refined-circuit-474617-s8"
          - region: "us-central1"
          - timestamp: ${string(int(sys.now()))}
          - execution_dir: ${"cumulative-execution-" + timestamp}
          - base_model: "gemini-2.5-pro"
          - model_prefix: "basketball-pro"

    - log_start:
        call: sys.log
        args:
          data: '${"üöÄ Starting cumulative training for " + string(len(game_ids)) + " games"}'
          severity: INFO

    # Step 1: Create JSONL files for each game that doesn't have them
    - create_missing_jsonl_files:
        for:
          value: game_id
          in: ${game_ids}
          steps:
            - check_and_create_jsonl:
                call: check_and_create_training_data
                args:
                  game_id: ${game_id}
                  project_id: ${project_id}
                  region: ${region}

    # Step 2: Combine all JSONL files (after ensuring they exist)
    - set_game_variables:
        assign:
          - game_ids_str: ""
    
    - build_game_ids_string:
        for:
          value: game_id
          in: ${game_ids}
          steps:
            - append_game_id:
                assign:
                  - game_ids_str: ${game_ids_str + game_id + ","}

    - combine_files:
        call: googleapis.run.v1.namespaces.jobs.create
        args:
          parent: '${"namespaces/" + project_id}'
          location: ${region}
          body:
            apiVersion: run.googleapis.com/v1
            kind: Job
            metadata:
              name: '${"combine-" + timestamp}'
            spec:
              template:
                spec:
                  parallelism: 1
                  taskCount: 1
                  template:
                    spec:
                      containers:
                      - image: "gcr.io/google.com/cloudsdktool/cloud-sdk:latest"
                        command: ["/bin/bash"]
                        args:
                          - "-c"
                          - |
                            echo "üöÄ Combining JSONL files from all games..."
                            
                            # Create execution directory
                            gsutil -m mkdir -p "gs://uball-training-data/${EXECUTION_DIR}/"
                            
                            # Initialize combined files (empty, not blank line)
                            touch /tmp/combined_training.jsonl
                            touch /tmp/combined_validation.jsonl
                            
                            # Process all games from comma-separated list
                            game_count=0
                            IFS=',' read -ra GAMES <<< "$GAME_IDS"
                            for game_id in "${GAMES[@]}"; do
                              game_count=$((game_count + 1))
                              echo "üìÇ Processing game $game_count: $game_id"
                              
                              # Create game directory in execution folder
                              gsutil -m mkdir -p "gs://uball-training-data/${EXECUTION_DIR}/${game_id}/"
                              
                              # Find and combine training files (get the most recent)
                              training_file=$(gsutil ls "gs://uball-training-data/games/$game_id/video_training_*.jsonl" 2>/dev/null | sort | tail -1 || echo "")
                              if [ -n "$training_file" ]; then
                                echo "üì• Downloading training file: $training_file"
                                gsutil cp "$training_file" "/tmp/game${game_count}_training.jsonl" 2>/dev/null || true
                                if [ -f "/tmp/game${game_count}_training.jsonl" ]; then
                                  # Remove 4-point shot references and clean up
                                  sed 's/4PT_MAKE/3PT_MAKE/g; s/4PT_MISS/3PT_MISS/g; s/‚ö†Ô∏è CRITICAL: This is UBALL basketball with a 4-POINT LINE\. 4-point shots are VALID and DIFFERENT from 3-point shots\.//g' "/tmp/game${game_count}_training.jsonl" >> /tmp/combined_training.jsonl
                                  echo "‚úÖ Added training data for game $game_id"
                                else
                                  echo "‚ùå Failed to download training file for game $game_id"
                                fi
                              else
                                echo "‚ö†Ô∏è No training file found for game $game_id"
                              fi
                              
                              # Find and combine validation files (get the most recent)
                              validation_file=$(gsutil ls "gs://uball-training-data/games/$game_id/video_validation_*.jsonl" 2>/dev/null | sort | tail -1 || echo "")
                              if [ -n "$validation_file" ]; then
                                echo "üì• Downloading validation file: $validation_file"
                                gsutil cp "$validation_file" "/tmp/game${game_count}_validation.jsonl" 2>/dev/null || true
                                if [ -f "/tmp/game${game_count}_validation.jsonl" ]; then
                                  # Remove 4-point shot references and clean up
                                  sed 's/4PT_MAKE/3PT_MAKE/g; s/4PT_MISS/3PT_MISS/g; s/‚ö†Ô∏è CRITICAL: This is UBALL basketball with a 4-POINT LINE\. 4-point shots are VALID and DIFFERENT from 3-point shots\.//g' "/tmp/game${game_count}_validation.jsonl" >> /tmp/combined_validation.jsonl
                                  echo "‚úÖ Added validation data for game $game_id"
                                else
                                  echo "‚ùå Failed to download validation file for game $game_id"
                                fi
                              else
                                echo "‚ö†Ô∏è No validation file found for game $game_id"
                              fi
                            done
                            
                            # Check if files have content
                            training_lines=$(wc -l < /tmp/combined_training.jsonl)
                            validation_lines=$(wc -l < /tmp/combined_validation.jsonl)
                            
                            echo "üìä Summary:"
                            echo "  - Processed games: $game_count"
                            echo "  - Training examples: $training_lines"
                            echo "  - Validation examples: $validation_lines"
                            
                            if [ "$training_lines" -eq 0 ]; then
                              echo "‚ùå No training data found! Cannot proceed."
                              exit 1
                            fi
                            
                            # Upload combined files
                            echo "üì§ Uploading combined files..."
                            gsutil cp /tmp/combined_training.jsonl "gs://uball-training-data/${EXECUTION_DIR}/combined_training.jsonl"
                            gsutil cp /tmp/combined_validation.jsonl "gs://uball-training-data/${EXECUTION_DIR}/combined_validation.jsonl"
                            
                            echo "‚úÖ Combined files ready with $game_count games!"
                        env:
                        - name: EXECUTION_DIR
                          value: ${execution_dir}
                        - name: GAME_IDS
                          value: ${game_ids_str}
                        resources:
                          limits:
                            memory: 4Gi
                            cpu: "2"
                      maxRetries: 3
                      timeoutSeconds: "1800"
        result: combine_job

    - run_combine_job:
        call: googleapis.run.v1.namespaces.jobs.run
        args:
          name: '${"namespaces/" + project_id + "/jobs/" + combine_job.metadata.name}'
          location: ${region}
        result: combine_execution

    - wait_combine:
        call: wait_job_complete
        args:
          execution_name: ${combine_execution.metadata.name}
          project_id: ${project_id}

    # Start Vertex AI tuning
    - set_file_paths:
        assign:
          - training_file: '${"gs://uball-training-data/" + execution_dir + "/combined_training.jsonl"}'
          - validation_file: '${"gs://uball-training-data/" + execution_dir + "/combined_validation.jsonl"}'
    
    - create_tuning_job:
        call: http.post
        args:
          url: '${"https://" + region + "-aiplatform.googleapis.com/v1/projects/" + project_id + "/locations/" + region + "/tuningJobs"}'
          auth:
            type: OAuth2
          headers:
            Content-Type: "application/json"
          body:
            baseModel: ${base_model}
            supervisedTuningSpec:
              trainingDatasetUri: ${training_file}
              validationDatasetUri: ${validation_file}
              hyperParameters:
                epochCount: "5"
                learningRateMultiplier: "1.0"
                adapterSize: "ADAPTER_SIZE_ONE"
            tunedModelDisplayName: '${"" + model_prefix + "-cumulative-" + string(len(game_ids)) + "games-" + timestamp}'
            description: '${"Cumulative training on " + string(len(game_ids)) + " games using " + base_model}'
        result: tuning_response

    - log_tuning_started:
        call: sys.log
        args:
          data: '${"ü§ñ Started tuning job: " + tuning_response.body.name}'
          severity: INFO

    # Monitor tuning completion
    - wait_tuning:
        call: monitor_tuning
        args:
          job_name: ${tuning_response.body.name}

    - log_success:
        call: sys.log
        args:
          data: '${"üéâ Cumulative training completed for " + string(len(game_ids)) + " games!"}'
          severity: INFO

    - return_result:
        return:
          success: true
          games_trained: ${game_ids}
          total_games: ${len(game_ids)}
          training_file: ${training_file}
          validation_file: ${validation_file}
          execution_directory: ${execution_dir}

# Wait for job completion
wait_job_complete:
  params: [execution_name, project_id]
  steps:
    - poll_loop:
        assign:
          - iterations: 0
          - max_iterations: 120  # 30s * 120 = 60 minutes
    - check_status:
        call: googleapis.run.v1.namespaces.executions.get
        args:
          name: '${"namespaces/" + project_id + "/executions/" + execution_name}'
          location: us-central1
        result: status
    - evaluate_status:
        switch:
          - condition: ${len(status.status.conditions) > 0 and status.status.conditions[0].type == "Completed"}
            return: ${status}
          - condition: ${len(status.status.conditions) > 0 and status.status.conditions[0].type == "Failed"}
            raise: '${"Execution failed: " + status.status.conditions[0].message}'
          - condition: ${iterations >= max_iterations}
            raise: "Execution timed out"
    - wait_and_retry:
        call: sys.sleep
        args:
          seconds: 30
    - increment_and_continue:
        assign:
          - iterations: ${iterations + 1}
        next: check_status

# Monitor tuning job
monitor_tuning:
  params: [job_name]
  steps:
    - poll_loop:
        assign:
          - iterations: 0
          - max_iterations: 480  # 1 minute * 480 = 8 hours
    - check_tuning:
        call: http.get
        args:
          url: '${"https://us-central1-aiplatform.googleapis.com/v1/" + job_name}'
          auth:
            type: OAuth2
        result: tuning_status
    - evaluate_tuning:
        switch:
          - condition: ${tuning_status.body.state == "JOB_STATE_SUCCEEDED"}
            return:
              success: true
              tuned_model: ${tuning_status.body.tunedModel.model}
          - condition: ${tuning_status.body.state == "JOB_STATE_FAILED"}
            raise: '${"Tuning failed: " + tuning_status.body.error.message}'
          - condition: ${iterations >= max_iterations}
            raise: "Tuning timed out"
    - wait_and_retry:
        call: sys.sleep
        args:
          seconds: 60
    - increment_and_continue:
        assign:
          - iterations: ${iterations + 1}
        next: check_tuning

# Check if training data exists for a game, create if missing
check_and_create_training_data:
  params: [game_id, project_id, region]
  steps:
    - log_checking_game:
        call: sys.log
        args:
          data: '${"üîç Checking training data for game: " + game_id}'
          severity: INFO
    
    - check_training_files:
        call: http.get
        args:
          url: '${"https://storage.googleapis.com/storage/v1/b/uball-training-data/o?prefix=games%2F" + game_id + "%2Fvideo_training_"}'
          auth:
            type: OAuth2
        result: training_check
    
    - check_validation_files:
        call: http.get
        args:
          url: '${"https://storage.googleapis.com/storage/v1/b/uball-training-data/o?prefix=games%2F" + game_id + "%2Fvideo_validation_"}'
          auth:
            type: OAuth2
        result: validation_check
    
    - evaluate_existing:
        switch:
          - condition: ${"items" in training_check.body and len(training_check.body.items) > 0 and "items" in validation_check.body and len(validation_check.body.items) > 0}
            steps:
              - log_found_existing:
                  call: sys.log
                  args:
                    data: '${"‚úÖ Found complete training data for game: " + game_id + " (training + validation files)"}'
                    severity: INFO
              - return_existing:
                  return: 
                    game_id: ${game_id}
                    status: "existing"
          - condition: true
            steps:
              - log_creating_new:
                  call: sys.log
                  args:
                    data: '${"üìù Creating training data for game: " + game_id}'
                    severity: INFO
              - create_training_data:
                  call: create_extract_clips_job
                  args:
                    game_id: ${game_id}
                    project_id: ${project_id}
                    region: ${region}
              - return_created:
                  return:
                    game_id: ${game_id}
                    status: "created"

# Create extract-clips job for a specific game
create_extract_clips_job:
  params: [game_id, project_id, region]
  steps:
    - create_job:
        call: googleapis.run.v1.namespaces.jobs.create
        args:
          parent: '${"namespaces/" + project_id}'
          location: ${region}
          body:
            apiVersion: run.googleapis.com/v1
            kind: Job
            metadata:
              name: '${"extract-clips-" + game_id + "-" + string(int(sys.now()))}'
            spec:
              template:
                spec:
                  parallelism: 1
                  taskCount: 1
                  template:
                    spec:
                      containers:
                      - image: "gcr.io/refined-circuit-474617-s8/extract-clips-job:latest"
                        env:
                        - name: GAME_ID
                          value: ${game_id}
                        - name: GCS_TRAINING_BUCKET
                          value: "uball-training-data"
                        - name: PROJECT_ID
                          value: ${project_id}
                        - name: SUPABASE_URL
                          value: "https://mhbrsftxvxxtfgbajrlc.supabase.co"
                        - name: SUPABASE_SERVICE_KEY
                          value: "***REMOVED_SUPABASE_KEY***"
                        resources:
                          limits:
                            memory: 8Gi
                            cpu: "4"
                      maxRetries: 2
                      timeoutSeconds: "21600"
        result: extract_job
    
    - run_extract_job:
        call: googleapis.run.v1.namespaces.jobs.run
        args:
          name: '${"namespaces/" + project_id + "/jobs/" + extract_job.metadata.name}'
          location: ${region}
        result: extract_execution
    
    - wait_extract_complete:
        call: wait_job_complete
        args:
          execution_name: ${extract_execution.metadata.name}
          project_id: ${project_id}
    
    - log_extract_complete:
        call: sys.log
        args:
          data: '${"‚úÖ Training data created for game: " + game_id}'
          severity: INFO
# Basketball Training Pipeline V3 - Fire-and-Forget + Polling Pattern
# Solves the timeout issue by triggering functions asynchronously and polling for completion

main:
  params: [args]
  steps:
    - init:
        assign:
          - game_ids: ${args.game_ids}
          - project_id: "refined-circuit-474617-s8"
          - region: "us-central1"
          - timestamp: ${string(int(sys.now()))}
          - execution_dir: ${"cumulative-execution-" + timestamp}
          - base_model: "gemini-2.5-pro"
          - model_prefix: "basketball-pro"
          - function_url: "https://us-central1-refined-circuit-474617-s8.cloudfunctions.net/extract-clips-game"

    - log_start:
        call: sys.log
        args:
          data: '${"üöÄ Starting cumulative training for " + string(len(game_ids)) + " games"}'
          severity: INFO

    # Step 1: Trigger all Cloud Functions asynchronously (fire-and-forget)
    - trigger_all_games:
        parallel:
          for:
            value: game_id
            in: ${game_ids}
            steps:
              - log_trigger_start:
                  call: sys.log
                  args:
                    data: '${"üöÄ Triggering extraction for game: " + game_id}'
                    severity: INFO

              - trigger_function:
                  try:
                    call: http.post
                    args:
                      url: ${function_url}
                      auth:
                        type: OAuth2
                      headers:
                        Content-Type: "application/json"
                      body:
                        game_id: ${game_id}
                      timeout: 10
                    result: trigger_response
                  except:
                    as: e
                    steps:
                      - log_trigger_note:
                          call: sys.log
                          args:
                            data: '${"‚è±Ô∏è Function triggered for " + game_id + " (may timeout, will poll for completion)"}'
                            severity: INFO

              - log_triggered:
                  call: sys.log
                  args:
                    data: '${"‚úÖ Function triggered for game: " + game_id}'
                    severity: INFO

    - log_all_triggered:
        call: sys.log
        args:
          data: "‚úÖ All Cloud Functions triggered! Now polling for completion..."
          severity: INFO

    # Step 2: Poll for completion by checking JSONL files in GCS
    - wait_for_all_games:
        call: poll_games_completion
        args:
          game_ids: ${game_ids}
          max_wait_minutes: 120

    - log_extraction_complete:
        call: sys.log
        args:
          data: "üéâ All games processed! Starting JSONL combination..."
          severity: INFO

    # Step 3: Combine JSONL files from all games
    - set_game_variables:
        assign:
          - game_ids_str: ""

    - build_game_ids_string:
        for:
          value: game_id
          in: ${game_ids}
          steps:
            - append_game_id:
                assign:
                  - game_ids_str: ${game_ids_str + game_id + ","}

    - combine_files:
        call: googleapis.run.v1.namespaces.jobs.create
        args:
          parent: '${"namespaces/" + project_id}'
          location: ${region}
          body:
            apiVersion: run.googleapis.com/v1
            kind: Job
            metadata:
              name: '${"combine-" + timestamp}'
            spec:
              template:
                spec:
                  parallelism: 1
                  taskCount: 1
                  template:
                    spec:
                      containers:
                      - image: "gcr.io/google.com/cloudsdktool/cloud-sdk:latest"
                        command: ["/bin/bash"]
                        args:
                          - "-c"
                          - |
                            echo "üöÄ Combining JSONL files from all games..."

                            # Create execution directory
                            gsutil -m mkdir -p "gs://uball-training-data/${EXECUTION_DIR}/"

                            # Initialize combined files
                            touch /tmp/combined_training.jsonl
                            touch /tmp/combined_validation.jsonl

                            # Process all games
                            game_count=0
                            IFS=',' read -ra GAMES <<< "$GAME_IDS"
                            for game_id in "${GAMES[@]}"; do
                              game_count=$((game_count + 1))
                              echo "üìÇ Processing game $game_count: $game_id"

                              # Find and combine training files (get the most recent)
                              training_file=$(gsutil ls "gs://uball-training-data/games/$game_id/video_training_*.jsonl" 2>/dev/null | sort | tail -1 || echo "")
                              if [ -n "$training_file" ]; then
                                echo "üì• Downloading training file: $training_file"
                                gsutil cp "$training_file" "/tmp/game${game_count}_training.jsonl" 2>/dev/null || true
                                if [ -f "/tmp/game${game_count}_training.jsonl" ]; then
                                  cat "/tmp/game${game_count}_training.jsonl" >> /tmp/combined_training.jsonl
                                  echo "‚úÖ Added training data for game $game_id"
                                fi
                              fi

                              # Find and combine validation files
                              validation_file=$(gsutil ls "gs://uball-training-data/games/$game_id/video_validation_*.jsonl" 2>/dev/null | sort | tail -1 || echo "")
                              if [ -n "$validation_file" ]; then
                                echo "üì• Downloading validation file: $validation_file"
                                gsutil cp "$validation_file" "/tmp/game${game_count}_validation.jsonl" 2>/dev/null || true
                                if [ -f "/tmp/game${game_count}_validation.jsonl" ]; then
                                  cat "/tmp/game${game_count}_validation.jsonl" >> /tmp/combined_validation.jsonl
                                  echo "‚úÖ Added validation data for game $game_id"
                                fi
                              fi
                            done

                            # Check results
                            training_lines=$(wc -l < /tmp/combined_training.jsonl)
                            validation_lines=$(wc -l < /tmp/combined_validation.jsonl)

                            echo "üìä Summary:"
                            echo "  - Processed games: $game_count"
                            echo "  - Training examples: $training_lines"
                            echo "  - Validation examples: $validation_lines"

                            if [ "$training_lines" -eq 0 ]; then
                              echo "‚ùå No training data found!"
                              exit 1
                            fi

                            # Upload combined files
                            echo "üì§ Uploading combined files..."
                            gsutil cp /tmp/combined_training.jsonl "gs://uball-training-data/${EXECUTION_DIR}/combined_training.jsonl"
                            gsutil cp /tmp/combined_validation.jsonl "gs://uball-training-data/${EXECUTION_DIR}/combined_validation.jsonl"

                            echo "‚úÖ Combined files ready!"
                        env:
                        - name: EXECUTION_DIR
                          value: ${execution_dir}
                        - name: GAME_IDS
                          value: ${game_ids_str}
                        resources:
                          limits:
                            memory: 4Gi
                            cpu: "2"
                      maxRetries: 3
                      timeoutSeconds: "1800"
        result: combine_job

    - run_combine_job:
        call: googleapis.run.v1.namespaces.jobs.run
        args:
          name: '${"namespaces/" + project_id + "/jobs/" + combine_job.metadata.name}'
          location: ${region}
        result: combine_execution

    - wait_combine:
        call: wait_job_complete
        args:
          execution_name: ${combine_execution.metadata.name}
          project_id: ${project_id}

    # Step 4: Start Vertex AI tuning
    - set_file_paths:
        assign:
          - training_file: '${"gs://uball-training-data/" + execution_dir + "/combined_training.jsonl"}'
          - validation_file: '${"gs://uball-training-data/" + execution_dir + "/combined_validation.jsonl"}'

    - create_tuning_job:
        call: http.post
        args:
          url: '${"https://" + region + "-aiplatform.googleapis.com/v1/projects/" + project_id + "/locations/" + region + "/tuningJobs"}'
          auth:
            type: OAuth2
          headers:
            Content-Type: "application/json"
          body:
            baseModel: ${base_model}
            supervisedTuningSpec:
              trainingDatasetUri: ${training_file}
              validationDatasetUri: ${validation_file}
              hyperParameters:
                epochCount: "5"
                learningRateMultiplier: "1.0"
                adapterSize: "ADAPTER_SIZE_ONE"
            tunedModelDisplayName: '${"" + model_prefix + "-cumulative-" + string(len(game_ids)) + "games-" + timestamp}'
            description: '${"Cumulative training on " + string(len(game_ids)) + " games using " + base_model}'
        result: tuning_response

    - log_tuning_started:
        call: sys.log
        args:
          data: '${"ü§ñ Started tuning job: " + tuning_response.body.name}'
          severity: INFO

    - wait_tuning:
        call: monitor_tuning
        args:
          job_name: ${tuning_response.body.name}

    - log_success:
        call: sys.log
        args:
          data: '${"üéâ Cumulative training completed for " + string(len(game_ids)) + " games!"}'
          severity: INFO

    - return_result:
        return:
          success: true
          games_trained: ${game_ids}
          total_games: ${len(game_ids)}
          training_file: ${training_file}
          validation_file: ${validation_file}
          execution_directory: ${execution_dir}

# Poll for game completion by checking GCS for JSONL files
poll_games_completion:
  params: [game_ids, max_wait_minutes]
  steps:
    - init_polling:
        assign:
          - completed_games: []
          - check_interval_seconds: 30
          - max_checks: ${max_wait_minutes * 2}
          - current_check: 0

    - poll_loop:
        steps:
          - increment_check:
              assign:
                - current_check: ${current_check + 1}

          - log_polling:
              call: sys.log
              args:
                data: '${"üîç Polling check " + string(current_check) + "/" + string(max_checks) + " | Completed: " + string(len(completed_games)) + "/" + string(len(game_ids))}'
                severity: INFO

          - check_each_game:
              for:
                value: game_id
                in: ${game_ids}
                steps:
                  - skip_if_completed:
                      switch:
                        - condition: ${game_id in completed_games}
                          next: continue

                  - check_game_files:
                      try:
                        call: http.get
                        args:
                          url: '${"https://storage.googleapis.com/storage/v1/b/uball-training-data/o?prefix=games%2F" + game_id + "%2Fvideo_training_"}'
                          auth:
                            type: OAuth2
                        result: files_check
                      except:
                        as: e
                        steps:
                          - assign_empty_result:
                              assign:
                                - files_check:
                                    body:
                                      items: []

                  - evaluate_completion:
                      switch:
                        - condition: ${"items" in files_check.body and len(files_check.body.items) > 0}
                          steps:
                            - mark_complete:
                                assign:
                                  - completed_games: ${list.concat(completed_games, game_id)}
                            - log_game_complete:
                                call: sys.log
                                args:
                                  data: '${"‚úÖ Game completed: " + game_id}'
                                  severity: INFO

          - check_all_complete:
              switch:
                - condition: ${len(completed_games) == len(game_ids)}
                  steps:
                    - log_all_complete:
                        call: sys.log
                        args:
                          data: '${"üéâ All " + string(len(game_ids)) + " games completed!"}'
                          severity: INFO
                    - return_success:
                        return:
                          success: true
                          completed_games: ${completed_games}

          - check_timeout:
              switch:
                - condition: ${current_check >= max_checks}
                  steps:
                    - log_timeout:
                        call: sys.log
                        args:
                          data: '${"‚ö†Ô∏è Timeout after " + string(max_wait_minutes) + " minutes. Completed: " + string(len(completed_games)) + "/" + string(len(game_ids))}'
                          severity: WARNING
                    - raise_timeout:
                        raise: '${"Timeout waiting for games. Completed: " + string(len(completed_games)) + "/" + string(len(game_ids))}'

          - wait_before_retry:
              call: sys.sleep
              args:
                seconds: ${check_interval_seconds}

          - next_iteration:
              next: poll_loop

# Wait for Cloud Run job completion
wait_job_complete:
  params: [execution_name, project_id]
  steps:
    - poll_loop:
        assign:
          - iterations: 0
          - max_iterations: 120
    - check_status:
        call: googleapis.run.v1.namespaces.executions.get
        args:
          name: '${"namespaces/" + project_id + "/executions/" + execution_name}'
          location: us-central1
        result: status
    - evaluate_status:
        switch:
          - condition: ${len(status.status.conditions) > 0 and status.status.conditions[0].type == "Completed"}
            return: ${status}
          - condition: ${len(status.status.conditions) > 0 and status.status.conditions[0].type == "Failed"}
            raise: '${"Execution failed: " + status.status.conditions[0].message}'
          - condition: ${iterations >= max_iterations}
            raise: "Execution timed out"
    - wait_and_retry:
        call: sys.sleep
        args:
          seconds: 30
    - increment_and_continue:
        assign:
          - iterations: ${iterations + 1}
        next: check_status

# Monitor Vertex AI tuning job
monitor_tuning:
  params: [job_name]
  steps:
    - poll_loop:
        assign:
          - iterations: 0
          - max_iterations: 480
    - check_tuning:
        call: http.get
        args:
          url: '${"https://us-central1-aiplatform.googleapis.com/v1/" + job_name}'
          auth:
            type: OAuth2
        result: tuning_status
    - evaluate_tuning:
        switch:
          - condition: ${tuning_status.body.state == "JOB_STATE_SUCCEEDED"}
            return:
              success: true
              tuned_model: ${tuning_status.body.tunedModel.model}
          - condition: ${tuning_status.body.state == "JOB_STATE_FAILED"}
            raise: '${"Tuning failed: " + tuning_status.body.error.message}'
          - condition: ${iterations >= max_iterations}
            raise: "Tuning timed out"
    - wait_and_retry:
        call: sys.sleep
        args:
          seconds: 60
    - increment_and_continue:
        assign:
          - iterations: ${iterations + 1}
        next: check_tuning

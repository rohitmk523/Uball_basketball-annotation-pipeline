# Hybrid Training Pipeline - Cloud Functions + Cloud Run Jobs
# This orchestrates the basketball annotation training pipeline using:
# 1. Cloud Function for fast database export
# 2. Cloud Run Jobs for heavy video/ML processing

main:
  params: [args]
  steps:
    - init:
        assign:
          - game_id: ${args.game_id}
          - project_id: "refined-circuit-474617-s8"
          - region: "us-central1"
          - timestamp: ${string(int(sys.now()))}
          - pipeline_id: ${"hybrid-pipeline-" + game_id + "-" + timestamp}

    - log_start:
        call: sys.log
        args:
          data: '${"üöÄ Starting hybrid training pipeline for game: " + game_id}'
          severity: INFO

    # Step 1: Cloud Function - Export plays from database
    - export_plays:
        call: http.post
        args:
          url: '${"https://" + region + "-" + project_id + ".cloudfunctions.net/export-plays-cf"}'
          headers:
            Content-Type: "application/json"
          body:
            game_id: ${game_id}
        result: export_result

    - check_export:
        switch:
          - condition: ${export_result.body.success}
            next: log_export_success
          - condition: true
            next: export_failed

    - log_export_success:
        call: sys.log
        args:
          data: '${"‚úÖ Export completed: " + string(export_result.body.total_plays) + " plays exported"}'
          severity: INFO

    # Step 2: Cloud Run Job - Extract video clips (with smart skipping)
    - extract_clips_job:
        call: googleapis.run.v1.namespaces.jobs.create
        args:
          parent: '${"namespaces/" + project_id}'
          location: ${region}
          body:
            apiVersion: run.googleapis.com/v1
            kind: Job
            metadata:
              name: '${"extract-clips-" + game_id + "-" + timestamp}'
            spec:
              template:
                spec:
                  parallelism: 1
                  taskCount: 1
                  template:
                    spec:
                      containers:
                      - image: '${"gcr.io/" + project_id + "/extract-clips:latest"}'
                        env:
                        - name: GAME_ID
                          value: ${game_id}
                        - name: PLAYS_FILE_GCS
                          value: ${export_result.body.files.all_plays}
                        - name: GCS_TRAINING_BUCKET
                          value: "uball-training-data"
                        - name: GCS_VIDEO_BUCKET
                          value: "uball-videos-production"
                        - name: SKIP_IF_EXISTS
                          value: "true"
                        resources:
                          limits:
                            memory: 16Gi
                            cpu: "8"
                      maxRetries: 3
                      timeoutSeconds: "86400"
        result: extract_job

    - log_extract_job_created:
        call: sys.log
        args:
          data: '${"üé¨ Created clip extraction job: " + extract_job.metadata.name}'
          severity: INFO

    # Execute the job
    - execute_extract_job:
        call: googleapis.run.v1.namespaces.jobs.run
        args:
          name: '${"namespaces/" + project_id + "/jobs/" + extract_job.metadata.name}'
          location: ${region}
        result: extract_execution

    - log_extract_job_started:
        call: sys.log
        args:
          data: '${"üöÄ Executing clip extraction job: " + extract_execution.metadata.name}'
          severity: INFO

    # Wait for clip extraction completion
    - wait_extract_completion:
        call: wait_for_execution_completion
        args:
          execution_name: ${extract_execution.metadata.name}
          project_id: ${project_id}
          timeout_minutes: 60  # 1 hour should be enough for clip extraction
        result: extract_status

    - log_extract_completion:
        call: sys.log
        args:
          data: '${"‚úÖ Clip extraction completed successfully"}'
          severity: INFO

    # Brief wait to ensure GCS indexing is complete
    - wait_for_gcs_indexing:
        call: sys.sleep
        args:
          seconds: 5

    # Step 3: Find existing training data files
    - find_training_files:
        call: find_latest_training_files
        args:
          game_id: ${game_id}
          project_id: ${project_id}
        result: training_files

    - log_training_files_found:
        call: sys.log
        args:
          data: '${"‚úÖ Found training files: " + training_files.training_file}'
          severity: INFO

    # Step 4: Determine base model for incremental training
    - get_base_model:
        call: get_latest_trained_model
        args:
          project_id: ${project_id}
        result: base_model_info

    - log_base_model:
        call: sys.log
        args:
          data: '${"üîÑ Using base model: " + base_model_info.model_name + " for incremental training"}'
          severity: INFO

    # Step 4: Direct Vertex AI Model Fine-tuning (Incremental)
    - create_tuning_job:
        call: http.post
        args:
          url: '${"https://" + region + "-aiplatform.googleapis.com/v1/projects/" + project_id + "/locations/" + region + "/tuningJobs"}'
          auth:
            type: OAuth2
          headers:
            Content-Type: "application/json"
          body:
            baseModel: ${base_model_info.model_name}  # Use latest trained model or base gemini
            supervisedTuningSpec:
              trainingDatasetUri: ${training_files.training_file}
              validationDatasetUri: ${training_files.validation_file}
              hyperParameters:
                epochCount: "3"  # Fewer epochs for incremental training
                learningRateMultiplier: "0.5"  # Lower learning rate for fine-tuning
                adapterSize: "ADAPTER_SIZE_ONE"
            tunedModelDisplayName: '${"basketball-model-incremental-" + game_id + "-" + timestamp}'
        result: tuning_job_response

    - log_tuning_job_created:
        call: sys.log
        args:
          data: '${"ü§ñ Created Vertex AI tuning job: " + tuning_job_response.body.name}'
          severity: INFO

    # Monitor tuning job progress
    - wait_tuning_completion:
        call: monitor_tuning_job
        args:
          job_name: ${tuning_job_response.body.name}
          project_id: ${project_id}
          region: ${region}
          timeout_minutes: 480  # 8 hours for training
        result: tuning_status

    - log_tuning_completion:
        call: sys.log
        args:
          data: '${"‚úÖ Vertex AI model fine-tuning completed successfully"}'
          severity: INFO

    # Step 5: Count games trained and determine version
    - count_trained_games:
        call: get_trained_games_count
        args:
          project_id: ${project_id}
        result: games_count

    - determine_model_version:
        assign:
          - total_games: ${games_count.total + 1}  # Include current game
          - version_number: ${int(total_games / 5) + 1}  # v2 at 5 games, v3 at 10, etc.
          - model_display_name: '${"basketball-model-v" + string(version_number) + "-" + string(total_games) + "games"}'

    - log_versioning_info:
        call: sys.log
        args:
          data: '${"üìä Model versioning: " + string(total_games) + " games trained, creating " + model_display_name}'
          severity: INFO

    # Step 6: Deploy model to persistent endpoint
    - deploy_to_persistent_endpoint:
        call: deploy_model_to_endpoint
        args:
          tuned_model_name: ${tuning_status.tuned_model}
          model_display_name: ${model_display_name}
          project_id: ${project_id}
          region: ${region}
        result: deployment_result

    - log_deployment_success:
        call: sys.log
        args:
          data: '${"üöÄ Model deployed to persistent endpoint: " + deployment_result.endpoint_name}'
          severity: INFO

    # Step 7: Update game count in storage
    - update_trained_games_count:
        call: store_trained_games_count
        args:
          project_id: ${project_id}
          total_games: ${total_games}
          game_id: ${game_id}
          model_name: ${model_display_name}

    # Success completion
    - log_pipeline_success:
        call: sys.log
        args:
          data: '${"üéâ Continuous training pipeline completed successfully for game: " + game_id}'
          severity: INFO

    - return_success:
        return:
          success: true
          pipeline_id: ${pipeline_id}
          game_id: ${game_id}
          export_result: ${export_result.body}
          extract_job_name: ${extract_job.metadata.name}
          tuning_job_name: ${tuning_job_response.body.name}
          tuned_model: ${tuning_status.tuned_model}
          deployed_model: ${model_display_name}
          total_games_trained: ${total_games}
          model_version: ${version_number}
          persistent_endpoint: ${deployment_result.endpoint_name}
          endpoint_url: ${deployment_result.endpoint_url}
          vertex_ai_console: '${"https://console.cloud.google.com/vertex-ai/models?project=" + project_id}'
          message: "Continuous training pipeline completed with automatic deployment"

    # Error handling
    - export_failed:
        call: sys.log
        args:
          data: '${"‚ùå Export failed: " + string(export_result.body.error)}'
          severity: ERROR
        next: return_failure

    - return_failure:
        return:
          success: false
          pipeline_id: ${pipeline_id}
          game_id: ${game_id}
          error: "Pipeline failed"
          message: "Hybrid training pipeline failed"

# Subworkflow to wait for Cloud Run Job Execution completion
wait_for_execution_completion:
  params: [execution_name, project_id, timeout_minutes]
  steps:
    - init_polling:
        assign:
          - poll_interval_seconds: 30
          - max_iterations: ${timeout_minutes * 2}  # 30s intervals
          - iteration: 0

    - poll_execution_status:
        call: googleapis.run.v1.namespaces.executions.get
        args:
          name: '${"namespaces/" + project_id + "/executions/" + execution_name}'
          location: us-central1
        result: execution_status

    - check_execution_completion:
        switch:
          - condition: ${len(execution_status.status.conditions) > 0 and execution_status.status.conditions[0].type == "Completed"}
            next: execution_completed
          - condition: ${len(execution_status.status.conditions) > 0 and execution_status.status.conditions[0].type == "Failed"}
            next: execution_failed
          - condition: ${iteration >= max_iterations}
            next: execution_timeout

    - log_execution_progress:
        call: sys.log
        args:
          data: '${"üîÑ Execution " + execution_name + " still running... (check " + string(iteration + 1) + "/" + string(max_iterations) + ")"}'
          severity: INFO

    - wait_and_retry:
        call: sys.sleep
        args:
          seconds: ${poll_interval_seconds}

    - increment_counter:
        assign:
          - iteration: ${iteration + 1}
        next: poll_execution_status

    - execution_completed:
        steps:
          - log_completion:
              call: sys.log
              args:
                data: '${"‚úÖ Execution " + execution_name + " completed successfully"}'
                severity: INFO
          - return_success:
              return: ${execution_status}

    - execution_failed:
        steps:
          - log_failure:
              call: sys.log
              args:
                data: '${"‚ùå Execution " + execution_name + " failed: " + execution_status.status.conditions[0].message}'
                severity: ERROR
          - raise_error:
              raise: '${"Execution failed: " + execution_status.status.conditions[0].message}'

    - execution_timeout:
        steps:
          - log_timeout:
              call: sys.log
              args:
                data: '${"‚è∞ Execution " + execution_name + " timed out after " + string(timeout_minutes) + " minutes"}'
                severity: ERROR
          - raise_timeout:
              raise: '${"Execution timed out after " + string(timeout_minutes) + " minutes"}'

# Legacy subworkflow for job definition polling (kept for compatibility)
wait_for_job_completion:
  params: [job_name, project_id, timeout_minutes]
  steps:
    - init_polling:
        assign:
          - poll_interval_seconds: 30
          - max_iterations: ${timeout_minutes * 2}  # 30s intervals
          - iteration: 0

    - poll_job_status:
        call: googleapis.run.v1.namespaces.jobs.get
        args:
          name: '${"namespaces/" + project_id + "/jobs/" + job_name}'
          location: us-central1
        result: job_status

    - check_job_completion:
        switch:
          - condition: ${len(job_status.status.conditions) > 0 and job_status.status.conditions[0].type == "Complete"}
            next: job_completed
          - condition: ${len(job_status.status.conditions) > 0 and job_status.status.conditions[0].type == "Failed"}
            next: job_failed
          - condition: ${iteration >= max_iterations}
            next: job_timeout

    - log_job_progress:
        call: sys.log
        args:
          data: '${"üîÑ Job " + job_name + " still running... (check " + string(iteration + 1) + "/" + string(max_iterations) + ")"}'
          severity: INFO

    - wait_and_retry:
        call: sys.sleep
        args:
          seconds: ${poll_interval_seconds}

    - increment_counter:
        assign:
          - iteration: ${iteration + 1}
        next: poll_job_status

    - job_completed:
        steps:
          - log_completion:
              call: sys.log
              args:
                data: '${"‚úÖ Job " + job_name + " completed successfully"}'
                severity: INFO
          - return_success:
              return: ${job_status}

    - job_failed:
        steps:
          - log_failure:
              call: sys.log
              args:
                data: '${"‚ùå Job " + job_name + " failed: " + job_status.status.conditions[0].message}'
                severity: ERROR
          - raise_error:
              raise: '${"Job failed: " + job_status.status.conditions[0].message}'

    - job_timeout:
        steps:
          - log_timeout:
              call: sys.log
              args:
                data: '${"‚è∞ Job " + job_name + " timed out after " + string(timeout_minutes) + " minutes"}'
                severity: ERROR
          - raise_timeout:
              raise: '${"Job timed out after " + string(timeout_minutes) + " minutes"}'

# Simplified format data step (could be converted to another job later)
format_data_step:
  params: [game_id, project_id]
  steps:
    - log_format_start:
        call: sys.log
        args:
          data: '${"üìù Formatting training data for game: " + game_id}'
          severity: INFO

    # For now, we'll simulate this step
    # In a real implementation, this could be another Cloud Run Job
    # or call the format_training_data script via Cloud Build
    
    - simulate_formatting:
        call: sys.sleep
        args:
          seconds: 5

    - log_format_complete:
        call: sys.log
        args:
          data: '${"‚úÖ Training data formatting completed (simulated)"}'
          severity: INFO

    - return_format_result:
        return:
          success: true
          message: "Training data formatted successfully"

# Subworkflow to monitor Vertex AI tuning job completion
monitor_tuning_job:
  params: [job_name, project_id, region, timeout_minutes]
  steps:
    - init_polling:
        assign:
          - poll_interval_seconds: 60  # Check every minute for tuning jobs
          - max_iterations: ${timeout_minutes}  # 1-minute intervals
          - iteration: 0

    - poll_tuning_status:
        call: http.get
        args:
          url: '${"https://" + region + "-aiplatform.googleapis.com/v1/" + job_name}'
          auth:
            type: OAuth2
        result: tuning_status

    - check_tuning_completion:
        switch:
          - condition: ${tuning_status.body.state == "JOB_STATE_SUCCEEDED"}
            next: tuning_completed
          - condition: ${tuning_status.body.state == "JOB_STATE_FAILED"}
            next: tuning_failed
          - condition: ${tuning_status.body.state == "JOB_STATE_CANCELLED"}
            next: tuning_cancelled
          - condition: ${iteration >= max_iterations}
            next: tuning_timeout

    - log_tuning_progress:
        call: sys.log
        args:
          data: '${"üîÑ Tuning job " + job_name + " state: " + tuning_status.body.state + " (check " + string(iteration + 1) + "/" + string(max_iterations) + ")"}'
          severity: INFO

    - wait_and_retry:
        call: sys.sleep
        args:
          seconds: ${poll_interval_seconds}

    - increment_counter:
        assign:
          - iteration: ${iteration + 1}
        next: poll_tuning_status

    - tuning_completed:
        steps:
          - log_completion:
              call: sys.log
              args:
                data: '${"‚úÖ Tuning job " + job_name + " completed successfully"}'
                severity: INFO
          - log_model_info:
              call: sys.log
              args:
                data: '${"üéØ Fine-tuned model: " + tuning_status.body.tunedModel.model}'
                severity: INFO
          - return_success:
              return: 
                success: true
                state: ${tuning_status.body.state}
                tuned_model: ${tuning_status.body.tunedModel.model}
                tuning_job: ${job_name}

    - tuning_failed:
        steps:
          - log_failure:
              call: sys.log
              args:
                data: '${"‚ùå Tuning job " + job_name + " failed: " + tuning_status.body.error.message}'
                severity: ERROR
          - raise_failure:
              raise: '${"Tuning job failed: " + tuning_status.body.error.message}'

    - tuning_cancelled:
        steps:
          - log_cancellation:
              call: sys.log
              args:
                data: '${"‚ö†Ô∏è Tuning job " + job_name + " was cancelled"}'
                severity: WARNING
          - raise_cancellation:
              raise: '${"Tuning job was cancelled: " + job_name}'

    - tuning_timeout:
        steps:
          - log_timeout:
              call: sys.log
              args:
                data: '${"‚è∞ Tuning job " + job_name + " timed out after " + string(timeout_minutes) + " minutes"}'
                severity: ERROR
          - raise_timeout:
              raise: '${"Tuning job timed out after " + string(timeout_minutes) + " minutes"}'

# Subworkflow to get count of games trained so far
get_trained_games_count:
  params: [project_id]
  steps:
    - get_count_from_storage:
        try:
          call: http.get
          args:
            url: '${"https://storage.googleapis.com/uball-training-data/metadata/games_count.json"}'
          result: count_response
        except:
          as: e
          steps:
            - log_no_count_file:
                call: sys.log
                args:
                  data: "üìù No games count file found, starting from 0"
                  severity: INFO
            - return_zero_count:
                return:
                  total: 0
                  games: []

    - parse_count:
        assign:
          - count_data: ${count_response.body}
        
    - return_count:
        return:
          total: ${count_data.total}
          games: ${count_data.games}

# Subworkflow to store updated games count
store_trained_games_count:
  params: [project_id, total_games, game_id, model_name]
  steps:
    - get_existing_data:
        call: get_trained_games_count
        args:
          project_id: ${project_id}
        result: existing_data

    - build_updated_data:
        assign:
          - updated_games: ${existing_data.games}
          - current_time: ${string(int(sys.now()))}
          
    - add_current_game:
        assign:
          - new_game_entry:
              game_id: ${game_id}
              model_name: ${model_name}
              timestamp: ${current_time}
          - updated_games: ${list.concat(updated_games, [new_game_entry])}

    - create_metadata:
        assign:
          - metadata: 
              total: ${total_games}
              games: ${updated_games}
              last_updated: ${current_time}

    - upload_to_storage:
        call: http.put
        args:
          url: "https://storage.googleapis.com/uball-training-data/metadata/games_count.json"
          headers:
            Content-Type: "application/json"
          body: ${metadata}
          auth:
            type: OAuth2

    - log_count_updated:
        call: sys.log
        args:
          data: '${"üìä Updated games count: " + string(total_games) + " total games"}'
          severity: INFO

# Subworkflow to deploy model to persistent endpoint
deploy_model_to_endpoint:
  params: [tuned_model_name, model_display_name, project_id, region]
  steps:
    - log_deployment_start:
        call: sys.log
        args:
          data: '${"üöÄ Deploying model " + model_display_name + " to persistent endpoint"}'
          severity: INFO

    # Check if persistent endpoint exists
    - get_endpoints:
        call: http.get
        args:
          url: '${"https://" + region + "-aiplatform.googleapis.com/v1/projects/" + project_id + "/locations/" + region + "/endpoints"}'
          auth:
            type: OAuth2
        result: endpoints_response

    - find_persistent_endpoint:
        assign:
          - persistent_endpoint: null
          - endpoint_name: "basketball-annotation-endpoint"
        
    - check_for_existing_endpoint:
        for:
          value: endpoint
          in: ${endpoints_response.body.endpoints}
          steps:
            - check_endpoint_name:
                switch:
                  - condition: ${endpoint.displayName == endpoint_name}
                    assign:
                      - persistent_endpoint: ${endpoint}

    # Create endpoint if it doesn't exist
    - create_endpoint_if_needed:
        switch:
          - condition: ${persistent_endpoint == null}
            steps:
              - create_persistent_endpoint:
                  call: http.post
                  args:
                    url: '${"https://" + region + "-aiplatform.googleapis.com/v1/projects/" + project_id + "/locations/" + region + "/endpoints"}'
                    auth:
                      type: OAuth2
                    headers:
                      Content-Type: "application/json"
                    body:
                      displayName: ${endpoint_name}
                      description: "Persistent endpoint for basketball annotation models"
                  result: create_endpoint_response
              
              - assign_new_endpoint:
                  assign:
                    - persistent_endpoint: ${create_endpoint_response.body}

              - log_endpoint_created:
                  call: sys.log
                  args:
                    data: '${"‚úÖ Created persistent endpoint: " + persistent_endpoint.name}'
                    severity: INFO

    # Deploy model to endpoint using correct Vertex AI API structure
    - deploy_model:
        call: http.post
        args:
          url: '${"https://" + region + "-aiplatform.googleapis.com/v1/" + persistent_endpoint.name + ":deployModel"}'
          auth:
            type: OAuth2
          headers:
            Content-Type: "application/json"
          body:
            deployedModel:
              model: ${tuned_model_name}
              displayName: ${model_display_name}
              dedicatedResources:
                machineSpec:
                  machineType: "n1-standard-2"
                minReplicaCount: 1
                maxReplicaCount: 3
            trafficSplit:
              "0": 100  # Route 100% traffic to new model
        result: deploy_response

    - log_deployment_complete:
        call: sys.log
        args:
          data: '${"‚úÖ Model deployed successfully to persistent endpoint"}'
          severity: INFO

    # Format endpoint URL for API usage
    - format_endpoint_url:
        assign:
          - endpoint_parts: ${text.split(persistent_endpoint.name, "/")}
          - endpoint_id: ${endpoint_parts[len(endpoint_parts) - 1]}
          - endpoint_url: '${"projects/" + project_id + "/locations/" + region + "/endpoints/" + endpoint_id}'

    - return_deployment_result:
        return:
          endpoint_name: ${persistent_endpoint.name}
          endpoint_url: ${endpoint_url}
          deployed_model_name: ${model_display_name}
          success: true

# Subworkflow to get the latest trained model for incremental training
get_latest_trained_model:
  params: [project_id]
  steps:
    - get_games_count:
        call: get_trained_games_count
        args:
          project_id: ${project_id}
        result: games_data

    - determine_base_model:
        switch:
          - condition: ${games_data.total == 0}
            # No games trained yet, use base Gemini model
            steps:
              - log_using_base_gemini:
                  call: sys.log
                  args:
                    data: "üéØ First training - using base Gemini 2.5 Flash model"
                    severity: INFO
              - return_base_model:
                  return:
                    model_name: "gemini-2.5-flash"
                    is_base_model: true
                    games_trained: 0
          - condition: true
            # Use the latest trained model from the deployed endpoint
            steps:
              - get_latest_deployed_model:
                  call: get_deployed_model_from_endpoint
                  args:
                    project_id: ${project_id}
                  result: deployed_model
              
              - log_using_latest_model:
                  call: sys.log
                  args:
                    data: '${"üîÑ Incremental training - using latest model: " + deployed_model.model_name}'
                    severity: INFO
              
              - return_latest_model:
                  return:
                    model_name: ${deployed_model.model_name}
                    is_base_model: false
                    games_trained: ${games_data.total}

# Subworkflow to get the currently deployed model from persistent endpoint
get_deployed_model_from_endpoint:
  params: [project_id]
  steps:
    - get_endpoints:
        call: http.get
        args:
          url: '${"https://us-central1-aiplatform.googleapis.com/v1/projects/" + project_id + "/locations/us-central1/endpoints"}'
          auth:
            type: OAuth2
        result: endpoints_response

    - find_basketball_endpoint:
        assign:
          - basketball_endpoint: null
        
    - search_for_endpoint:
        for:
          value: endpoint
          in: ${endpoints_response.body.endpoints}
          steps:
            - check_endpoint_name:
                switch:
                  - condition: ${endpoint.displayName == "basketball-annotation-endpoint"}
                    assign:
                      - basketball_endpoint: ${endpoint}

    - handle_no_endpoint:
        switch:
          - condition: ${basketball_endpoint == null}
            steps:
              - log_no_endpoint:
                  call: sys.log
                  args:
                    data: "‚ö†Ô∏è No persistent endpoint found, using base Gemini model"
                    severity: WARNING
              - return_base_model_fallback:
                  return:
                    model_name: "gemini-2.5-flash"
                    is_base_model: true

    # Get deployed models from the endpoint
    - get_deployed_models:
        call: http.get
        args:
          url: '${"https://us-central1-aiplatform.googleapis.com/v1/" + basketball_endpoint.name + "/deployedModels"}'
          auth:
            type: OAuth2
        result: deployed_models_response

    - find_latest_model:
        assign:
          - latest_model: null
          - latest_timestamp: 0

    - search_deployed_models:
        for:
          value: deployed_model
          in: ${deployed_models_response.body.deployedModels}
          steps:
            - check_model_timestamp:
                switch:
                  - condition: ${int(deployed_model.createTime) > latest_timestamp}
                    assign:
                      - latest_model: ${deployed_model}
                      - latest_timestamp: ${int(deployed_model.createTime)}

    - return_latest_deployed_model:
        switch:
          - condition: ${latest_model != null}
            return:
              model_name: ${latest_model.model}
              is_base_model: false
              deployed_model_id: ${latest_model.id}
          - condition: true
            # Fallback to base model if no deployed models found
            return:
              model_name: "gemini-2.5-flash"
              is_base_model: true


# Subworkflow to find the latest training files for a game
find_latest_training_files:
  params: [game_id, project_id]
  steps:
    - log_finding_files:
        call: sys.log
        args:
          data: '${"üîç Finding training files for game: " + game_id}'
          severity: INFO

    # List training files
    - list_training_files:
        call: http.get
        args:
          url: '${"https://storage.googleapis.com/storage/v1/b/uball-training-data/o?prefix=games%2F" + game_id + "%2Fvideo_training_"}'
          auth:
            type: OAuth2
        result: training_response

    # List validation files  
    - list_validation_files:
        call: http.get
        args:
          url: '${"https://storage.googleapis.com/storage/v1/b/uball-training-data/o?prefix=games%2F" + game_id + "%2Fvideo_validation_"}'
          auth:
            type: OAuth2
        result: validation_response

    - extract_training_files:
        switch:
          - condition: ${"items" in training_response.body}
            assign:
              - training_files: ${training_response.body.items}
          - condition: true
            assign:
              - training_files: []
    
    - extract_validation_files:
        switch:
          - condition: ${"items" in validation_response.body}
            assign:
              - validation_files: ${validation_response.body.items}
          - condition: true
            assign:
              - validation_files: []

    - log_file_counts:
        call: sys.log
        args:
          data: '${"üìä Found " + string(len(training_files)) + " training files, " + string(len(validation_files)) + " validation files"}'
          severity: INFO

    - check_files_exist:
        switch:
          - condition: ${len(training_files) > 0 and len(validation_files) > 0}
            steps:
              # Get the latest files (they have timestamps in filenames, so we'll use the first available)
              - get_latest_training:
                  assign:
                    - latest_training: ${training_files[0]}  # Use first available
                    - latest_validation: ${validation_files[0]}  # Use first available  
                    - training_file_uri: '${"gs://uball-training-data/" + latest_training.name}'
                    - validation_file_uri: '${"gs://uball-training-data/" + latest_validation.name}'

              - log_files_found:
                  call: sys.log
                  args:
                    data: '${"‚úÖ Found training files: " + latest_training.name}'
                    severity: INFO

              - return_files:
                  return:
                    training_file: ${training_file_uri}
                    validation_file: ${validation_file_uri}
                    training_name: ${latest_training.name}
                    validation_name: ${latest_validation.name}
          - condition: true
            steps:
              - log_no_files:
                  call: sys.log
                  args:
                    data: '${"‚ùå No training files found for game: " + game_id}'
                    severity: ERROR
              - raise_no_files:
                  raise: '${"No training files found for game: " + game_id}'